{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[new_ROS_V2] UCSD_pemodelan_ensemble_learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azizeko29/new_deteksi_fraud/blob/master/%5Bnew_ROS_V2%5D_UCSD_pemodelan_ensemble_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "DA-5b8e13OZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "# import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "import math\n",
        "import collections\n",
        "import time\n",
        "from scipy import stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "dlNO6PTS3OZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %matplotlib inline\n",
        "# from IPython.display import display\n",
        "# from sklearn import metrics\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.metrics import mean_squared_error\n",
        "# from statistics import stdev\n",
        "\n",
        "from sklearn import tree\n",
        "\n",
        "from IPython.display import Image  \n",
        "from sklearn.externals.six import StringIO  \n",
        "import pydotplus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nu2Fi203OZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXbdF63H3OZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def confussion_matrik(actual,predict):\n",
        "    TP,FP,FN,TN = 0,0,0,0\n",
        "    for i,val in enumerate(actual):\n",
        "        if val == 0:\n",
        "            if val == predict[i]:\n",
        "                TN += 1\n",
        "            else:\n",
        "                FP += 1\n",
        "        if val == 1:\n",
        "            if val == predict[i]:\n",
        "                TP += 1\n",
        "            else:\n",
        "                FN += 1\n",
        "    return TP,FP,FN,TN\n",
        " \n",
        "def acc_sens_spec(actual,predict):\n",
        "    TP,FP,FN,TN = confussion_matrik(actual,predict)\n",
        "# akurasi\n",
        "    if (TP+FP+FN+TN) == 0 :\n",
        "        accuracy = 0 \n",
        "    else :\n",
        "        accuracy = (TP+TN)/(TP+FP+FN+TN)\n",
        "        \n",
        "# sensitivity\n",
        "    if (TP+FN) == 0 :\n",
        "        sensitivity = 0\n",
        "    else :\n",
        "        sensitivity = TP/(TP+FN)\n",
        "        \n",
        "# specifity    \n",
        "    if (TN +FP) == 0 :\n",
        "        specifity = 0\n",
        "    else :\n",
        "        specifity = TN/(TN +FP)\n",
        "        \n",
        "# precision\n",
        "    if (TP+FP) == 0 :\n",
        "        precision = 0\n",
        "    else :\n",
        "        precision = TP/(TP+FP)\n",
        "\n",
        "# recall\n",
        "    recall = sensitivity\n",
        "\n",
        "# f1_score\n",
        "    if (precision+recall) == 0 :\n",
        "        f1_score = 0\n",
        "    else :\n",
        "        f1_score = 2*((precision*recall)/(precision+recall))  \n",
        "    \n",
        "    return accuracy,sensitivity,specifity,precision,recall,f1_score\n",
        "\n",
        "# Calculate accuracy percentage\n",
        "def accuracy_metric(actual, predicted):\n",
        "    #how many correct predictions?\n",
        "    correct = 0\n",
        "    #for each actual label\n",
        "    for i in range(len(actual)):\n",
        "        #if actual matches predicted label\n",
        "        if actual[i] == predicted[i]:\n",
        "            #add 1 to the correct iterator\n",
        "            correct += 1\n",
        "    #return percentage of predictions that were correct\n",
        "    return correct / float(len(actual)) * 100.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJRIgaWu3OZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# confussion_matrik(y,pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjDccmJj3OZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# accuracy,sensitivity,specifity = acc_sens_spec(y,pred)\n",
        "# print('acc',accuracy)\n",
        "# print('sens',sensitivity)\n",
        "# print('spec',specifity)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "KJOxP5wX3OZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# accuracy_metric(y,RF.predict(X))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F9KdIWf3OZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cross_val_split(X,fold=2,seed=0):\n",
        "    np.random.seed(seed)\n",
        "    n_folds= fold\n",
        "    size = X.shape[0]/n_folds\n",
        "    X_idx = list(range(X.shape[0]))\n",
        "    folds_data= []\n",
        "    for i in range(n_folds):\n",
        "#         print(X_idx)\n",
        "        random_idx = list(np.random.choice(X_idx,int(size),replace=False))\n",
        "#         print(random_idx)\n",
        "        X_idx = [idx for idx in X_idx if idx not in random_idx]\n",
        "#         print(X_idx)\n",
        "\n",
        "        folds_data.append(random_idx)\n",
        "#         print(\"--\")\n",
        "    return folds_data\n",
        "\n",
        "def kfold_cross_validation(model,X,y, n_fold=2, n_seed=0):\n",
        "    folds = cross_val_split(X,fold=n_fold,seed=n_seed)\n",
        "    fold_result =[]\n",
        "    for i in range(len(folds)):\n",
        "    #     print(i)\n",
        "        train = []\n",
        "        for j in range(len(folds)):\n",
        "            if j != i:\n",
        "                train = train + folds[j]\n",
        "        test = folds[i]\n",
        "\n",
        "        X_train = X.iloc[train,:].reset_index(drop=True)\n",
        "        y_train = y[train].reset_index(drop=True)\n",
        "\n",
        "        X_test = X.iloc[test,:].reset_index(drop=True)\n",
        "        y_test = y[test].reset_index(drop=True)\n",
        "\n",
        "\n",
        "        t0 = time.time()\n",
        "        model.fit(X_train, y_train)\n",
        "        t1 = time.time()\n",
        "        waktu = t1 - t0\n",
        "\n",
        "        predict = model.predict(X_test)\n",
        "        accuracy,sensitivity,specifity,precision,recall,f1_score = acc_sens_spec(y_test,predict)\n",
        "\n",
        "        result = [accuracy,sensitivity,specifity,precision,recall,f1_score,waktu]\n",
        "        fold_result.append(result)\n",
        "        \n",
        "    return fold_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiR9UJfnNnnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testing(model,X_test,y_test):\n",
        "    result_ = []\n",
        "\n",
        "#       t0 = time.time()\n",
        "#       model.fit(X_train, y_train)\n",
        "#       t1 = time.time()\n",
        "#       waktu = t1 - t0\n",
        "    predict = model.predict(X_test)\n",
        "    accuracy,sensitivity,specifity,precision,recall,f1_score = acc_sens_spec(y_test,predict)\n",
        "\n",
        "    result = [accuracy,sensitivity,specifity,precision,recall,f1_score]\n",
        "        \n",
        "    result_.append(result)\n",
        "        \n",
        "    return result_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXcyImFV3OZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.decomposition import PCA\n",
        "# import pylab as pl\n",
        "# def plot_this(X_rs,y_rs,method):\n",
        "#   # Use principal component to condense the 10 features to 2 features\n",
        "#   pca = PCA(n_components=2).fit(X_rs)\n",
        "#   pca_2d = pca.transform(X_rs)\n",
        "#   # Assign colors\n",
        "#   for i in range(0, pca_2d.shape[0]):\n",
        "#     if y_rs[i] == 0:\n",
        "#       c1 = pl.scatter(pca_2d[i,0],pca_2d[i,1],c='r', marker='o')\n",
        "#     elif y_rs[i] == 1:\n",
        "#       c2 = pl.scatter(pca_2d[i,0],pca_2d[i,1],c='g', marker='*')  \n",
        "#   pl.legend([c1, c2], ['Class 1', 'Class 2'])\n",
        "#   pl.title(method)\n",
        "#   pl.axis([-4, 5, -4, 4])  # x axis (-4,5), y axis (-4,4)\n",
        "#   pl.show()\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzoQL3J93OaC",
        "colab_type": "text"
      },
      "source": [
        "## ---------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MIdGmzb3OaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ##read data\n",
        "\n",
        "# train = pd.read_csv('data/ucsd_fico_train.csv',sep=\",\")\n",
        "\n",
        "# test = pd.DataFrame({'0': [0]})\n",
        "# test_ = pd.read_csv('data/ucsd_fico_test.csv',sep=\",\")\n",
        "# test = test.append(test_)\n",
        "# test = test.reset_index(drop=True)\n",
        "\n",
        "# df = train.copy()\n",
        "# df['Class'] = test\n",
        "# # df = pd.read_csv('data/sample_data.csv',sep=\",\")\n",
        "\n",
        "# # df0 = df.copy()\n",
        "# # df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nF4ekQg2TQ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "32631a29-8bfa-4016-d2e0-729735f4a1ac"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kLVX1Pc3LbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ##read data\n",
        "\n",
        "df_train = pd.read_csv('drive/My Drive/Deteksi fraud/data/UCSD_preprocessing_train.csv',sep=\";\")\n",
        "\n",
        "# read_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iRb8k9l6E7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ##read data\n",
        "\n",
        "df_test = pd.read_csv('drive/My Drive/Deteksi fraud/data/UCSD_preprocessing_test.csv',sep=\";\")\n",
        "\n",
        "# read_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd3IwMv03aFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xicmF6B32_34",
        "colab_type": "text"
      },
      "source": [
        "## --"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hB8iIvz3Obs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = df_test.drop('Class', axis=1)\n",
        "y_test = df_test['Class'].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttcCg9el3Obv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_new = df_train.drop('Class', axis=1)\n",
        "y_new = df_train['Class'].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFf0Y6hk3Oby",
        "colab_type": "code",
        "outputId": "23377395-cb01-4122-ff6b-96543983caa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "y_new.value_counts()"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    837\n",
              "0    837\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvLTOgqn3Ob3",
        "colab_type": "code",
        "outputId": "0edb76fb-526b-46d7-b5c5-86f2c1518f87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "X_new.columns"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['amount', 'hour1', 'zip1', 'field1', 'field2', 'flag1', 'field3',\n",
              "       'field4', 'indicator1', 'indicator2', 'flag2', 'flag3', 'flag4',\n",
              "       'flag5'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCagyUAT3OcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhfc3c9v3OcC",
        "colab_type": "text"
      },
      "source": [
        "# # k-folds\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRTIkHWU3OcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validasi_model (clf,X,y,kfolds):\n",
        "    CV_SKLearn = kfold_cross_validation(clf,X,y,n_fold=kfolds,n_seed=1)\n",
        "    df_result = pd.DataFrame(data= CV_SKLearn, columns=['Akurasi','Sensitivity','Specifity','precision','recall','f1_score','Waktu'])\n",
        "\n",
        "    df_result.insert(loc=0, column='No', value=list(range(1,df_result.shape[0]+1)))\n",
        "    df_result = df_result.set_index('No')\n",
        "\n",
        "    del df_result.index.name\n",
        "\n",
        "    df_result = df_result.append(df_result.describe()[1:2])\n",
        "    \n",
        "    return df_result\n",
        "# result_SKLearn = result_SKLearn.append('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsNMZt1V3OcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Classifier Libraries\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "    \n",
        "clf_RF = RandomForestClassifier(random_state=1,n_estimators=50)\n",
        "clf_AB = AdaBoostClassifier(random_state=1,n_estimators=100)\n",
        "clf_B = BaggingClassifier(random_state=1,n_estimators=100)\n",
        "clf_ET = ExtraTreesClassifier(random_state=1,n_estimators=100)\n",
        "clf_GB = GradientBoostingClassifier(random_state=1,n_estimators=100, max_depth=9)\n",
        "\n",
        "##skenario \n",
        "skenario_1 = {}\n",
        "skenario_1['1'] = clf_RF\n",
        "# skenario_1['2'] = clf_AB\n",
        "# skenario_1['3'] = clf_B\n",
        "# skenario_1['4'] = clf_ET\n",
        "skenario_1['5'] = clf_GB\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSQFMa4I8q6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# result = {}\n",
        "# for i in skenario_1:\n",
        "  \n",
        "#     clf_skenario = skenario_1[i]\n",
        "#     result[i] = validasi_model(clf_skenario,X_new,y_new,5)\n",
        "                \n",
        "\n",
        "# df_result = pd.DataFrame()\n",
        "# for i in skenario_1:\n",
        "#     df_result = df_result.append(result[i].iloc[5:,:])\n",
        "    \n",
        "# df_result.insert(loc=0, column='No', value=list(range(df_result.shape[0])))\n",
        "# df_result = df_result.set_index('No')\n",
        "\n",
        "# del df_result.index.name\n",
        "\n",
        "# df_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL1pZPas359P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "617d46ff-8663-4bf7-f776-8bf6250d9870"
      },
      "source": [
        "for i in skenario_1:\n",
        "    \n",
        "    clf_skenario = skenario_1[i]\n",
        "#     print('komposisi', i)\n",
        "\n",
        "    \n",
        "    result_SKLearn = validasi_model(clf_skenario,X_new,y_new,5)\n",
        "#     print(result_SKLearn)\n",
        "    \n",
        "    nama_file = 'drive/My Drive/Deteksi fraud/hasil/ROS/UCSD/k_folds/komposisi999.csv'\n",
        "    nama_file = nama_file.replace('999',str(i))\n",
        "\n",
        "    result_SKLearn.to_csv(nama_file, sep=';',index=False)\n",
        "                \n",
        "\n",
        "df_result = pd.DataFrame()\n",
        "for i in skenario_1:\n",
        "    nama_file = 'drive/My Drive/Deteksi fraud/hasil/ROS/UCSD/k_folds/komposisi999.csv'\n",
        "    nama_file = nama_file.replace('999',str(i))\n",
        "    df_komposisi = pd.read_csv(nama_file,sep=\";\")\n",
        "    df_result = df_result.append(df_komposisi.iloc[5:,:])\n",
        "    \n",
        "df_result.insert(loc=0, column='No', value=list(range(df_result.shape[0])))\n",
        "df_result = df_result.set_index('No')\n",
        "\n",
        "del df_result.index.name\n",
        "\n",
        "df_result.to_csv('drive/My Drive/Deteksi fraud/hasil/ROS/UCSD/k_folds/result.csv', sep=';',index=False)\n",
        "df_result      \n"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Akurasi</th>\n",
              "      <th>Sensitivity</th>\n",
              "      <th>Specifity</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>Waktu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.74012</td>\n",
              "      <td>0.711157</td>\n",
              "      <td>0.769200</td>\n",
              "      <td>0.754850</td>\n",
              "      <td>0.711157</td>\n",
              "      <td>0.731554</td>\n",
              "      <td>0.099232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.74012</td>\n",
              "      <td>0.728777</td>\n",
              "      <td>0.751834</td>\n",
              "      <td>0.746636</td>\n",
              "      <td>0.728777</td>\n",
              "      <td>0.736623</td>\n",
              "      <td>0.842650</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Akurasi  Sensitivity  Specifity  precision    recall  f1_score     Waktu\n",
              "0  0.74012     0.711157   0.769200   0.754850  0.711157  0.731554  0.099232\n",
              "1  0.74012     0.728777   0.751834   0.746636  0.728777  0.736623  0.842650"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY88k9oH3Oce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importances = clf.feature_importances_\n",
        "# indices = np.argsort(importances)[::-1]\n",
        "# fitur_importance =[]\n",
        "# for f in range(X_new.shape[1]):\n",
        "#     if  importances[indices[f]] > 0 :\n",
        "#         fitur_importance.append([X_new.columns[indices[f]],importances[indices[f]]])\n",
        "#         print(\"%2d) %-*s %f\" % (f + 1, 30,\n",
        "#         X_new.columns[indices[f]],\n",
        "#         importances[indices[f]]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iieHLGD3Och",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_FI = pd.DataFrame(data=fitur_importance,columns=['fitur','value'])\n",
        "# # np.array(df_FI['fitur'])\n",
        "# df_FI"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyHMPoVTPP1l",
        "colab_type": "text"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5ozIM9EPPxY",
        "colab_type": "text"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0Du8-1gPTv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validasi_testing (clf,X,y):\n",
        "    testing_result = testing(clf,X,y)\n",
        "    df_result = pd.DataFrame(data= testing_result, columns=['Akurasi','Sensitivity','Specifity','precision','recall','f1_score'])\n",
        "\n",
        "    df_result.insert(loc=0, column='No', value=list(range(1,df_result.shape[0]+1)))\n",
        "    df_result = df_result.set_index('No')\n",
        "\n",
        "    del df_result.index.name\n",
        "\n",
        "#     df_result = df_result.append(df_result.describe()[1:2])\n",
        "    \n",
        "    return df_result\n",
        "# result_SKLearn = result_SKLearn.append('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byPedOS4PTtZ",
        "colab_type": "code",
        "outputId": "20e62f00-93c3-4c72-9028-6abd7e33fdc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "n_tree = 100\n",
        "# clf_RF_ = RandomForestClassifier(random_state=1,n_estimators=n_tree, max_features='sqrt')\n",
        "clf_RF.fit(X_new,y_new)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
              "                       n_jobs=None, oob_score=False, random_state=1, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Neu8gCbsPTq0",
        "colab_type": "code",
        "outputId": "8ed15508-014a-4153-a0f8-b4cdba2fc3df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "n_tree = 100\n",
        "# clf = RandomForestClassifier(random_state=1,n_estimators=n_tree, max_features='sqrt')\n",
        "# clf_GB = GradientBoostingClassifier(random_state=1,n_estimators=50)\n",
        "\n",
        "clf_GB.fit(X_new,y_new)\n",
        "\n"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
              "                           learning_rate=0.1, loss='deviance', max_depth=9,\n",
              "                           max_features=None, max_leaf_nodes=None,\n",
              "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                           min_samples_leaf=1, min_samples_split=2,\n",
              "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                           n_iter_no_change=None, presort='auto',\n",
              "                           random_state=1, subsample=1.0, tol=0.0001,\n",
              "                           validation_fraction=0.1, verbose=0,\n",
              "                           warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV9Pyow1PTod",
        "colab_type": "code",
        "outputId": "715d0417-279e-4277-8d1e-c9855f063e46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "result = {}\n",
        "for i in skenario_1:\n",
        "  \n",
        "    clf_skenario = skenario_1[i]\n",
        "    result[i] = validasi_testing(clf_skenario,X_test,y_test)\n",
        "    \n",
        "                \n",
        "df_result = pd.DataFrame()\n",
        "for i in skenario_1:\n",
        "    df_result = df_result.append(result[i])\n",
        "    \n",
        "df_result.insert(loc=0, column='No', value=list(range(df_result.shape[0])))\n",
        "df_result = df_result.set_index('No')\n",
        "\n",
        "del df_result.index.name\n",
        "\n",
        "nama_file = 'drive/My Drive/Deteksi fraud/hasil/ROS/UCSD/testing/result.csv'\n",
        "\n",
        "df_result.to_csv(nama_file, sep=';',index=False)\n",
        "\n",
        "df_result"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Akurasi</th>\n",
              "      <th>Sensitivity</th>\n",
              "      <th>Specifity</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.802623</td>\n",
              "      <td>0.704735</td>\n",
              "      <td>0.805572</td>\n",
              "      <td>0.098444</td>\n",
              "      <td>0.704735</td>\n",
              "      <td>0.172755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.790404</td>\n",
              "      <td>0.724234</td>\n",
              "      <td>0.792397</td>\n",
              "      <td>0.095099</td>\n",
              "      <td>0.724234</td>\n",
              "      <td>0.168122</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Akurasi  Sensitivity  Specifity  precision    recall  f1_score\n",
              "0  0.802623     0.704735   0.805572   0.098444  0.704735  0.172755\n",
              "1  0.790404     0.724234   0.792397   0.095099  0.724234  0.168122"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6nIJpoPOd-F",
        "colab_type": "text"
      },
      "source": [
        "-------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFEEoptNOd6w",
        "colab_type": "text"
      },
      "source": [
        "**Testing balance data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyB0euiSPTl2",
        "colab_type": "code",
        "outputId": "bc7bcb47-aa6a-45d2-a063-ff0dceca44ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "y_test.value_counts()"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    11917\n",
              "1      359\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buQNL5LjPTju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test = X_test.copy()\n",
        "df_test['Class'] = y_test.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY5OndpePTgv",
        "colab_type": "code",
        "outputId": "d426e268-bffa-4b2b-f9b2-77f89da30e4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# Since our classes are highly skewed we should make them equivalent in order to have a normal distribution of the classes.\n",
        "\n",
        "# Lets shuffle the data before creating the subsamples\n",
        "df_copy = df_test.copy()\n",
        "# df_copy = df_copy.sample(frac=1)\n",
        "\n",
        "fraud_df = df_copy.loc[df_copy['Class'] == 1].sample(n=85295,random_state=1,replace=True)\n",
        "non_fraud_df = df_copy.loc[df_copy['Class'] == 0]\n",
        "\n",
        "# fraud_df = df_copy.loc[df_copy['Class'] == 1]\n",
        "# non_fraud_df = df_copy.loc[df_copy['Class'] == 0].sample(n=11917,random_state=1)\n",
        "\n",
        "normal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n",
        "\n",
        "# Shuffle dataframe rows\n",
        "df_new = normal_distributed_df.sample(frac=1, random_state=1)\n",
        "df_new = df_new.reset_index()\n",
        "df_new = df_new.drop('index', axis=1)\n",
        "df_new.head()"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>amount</th>\n",
              "      <th>hour1</th>\n",
              "      <th>zip1</th>\n",
              "      <th>field1</th>\n",
              "      <th>field2</th>\n",
              "      <th>flag1</th>\n",
              "      <th>field3</th>\n",
              "      <th>field4</th>\n",
              "      <th>indicator1</th>\n",
              "      <th>indicator2</th>\n",
              "      <th>flag2</th>\n",
              "      <th>flag3</th>\n",
              "      <th>flag4</th>\n",
              "      <th>flag5</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>38.85</td>\n",
              "      <td>23</td>\n",
              "      <td>852</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3393</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12.95</td>\n",
              "      <td>18</td>\n",
              "      <td>337</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4670</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10.36</td>\n",
              "      <td>11</td>\n",
              "      <td>891</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3605</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12.95</td>\n",
              "      <td>15</td>\n",
              "      <td>816</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2150</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10.36</td>\n",
              "      <td>21</td>\n",
              "      <td>633</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2613</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   amount  hour1  zip1  field1  field2  ...  flag2  flag3  flag4  flag5  Class\n",
              "0   38.85     23   852       3       1  ...      0      0      0      1      1\n",
              "1   12.95     18   337       3       1  ...      1      1      0      1      0\n",
              "2   10.36     11   891       3       0  ...      0      0      0      1      1\n",
              "3   12.95     15   816       3       0  ...      1      1      0      1      1\n",
              "4   10.36     21   633       0       0  ...      1      0      0      2      1\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqutyh0pQQ_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_ = df_new.drop('Class', axis=1)\n",
        "y_test_ = df_new['Class'].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIx2jEC9PTeL",
        "colab_type": "code",
        "outputId": "16671801-a68a-4b3c-90e7-1926fdc815be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "y_test_.value_counts()"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    85295\n",
              "0    11917\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6_h4CrPQVCM",
        "colab_type": "code",
        "outputId": "abf96327-be5b-4fa7-fe29-afc1ad717485",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "result = {}\n",
        "for i in skenario_1:\n",
        "  \n",
        "    clf_skenario = skenario_1[i]\n",
        "    result[i] = validasi_testing(clf_skenario,X_test_,y_test_)\n",
        "    \n",
        "                \n",
        "df_result = pd.DataFrame()\n",
        "for i in skenario_1:\n",
        "    df_result = df_result.append(result[i])\n",
        "    \n",
        "df_result.insert(loc=0, column='No', value=list(range(df_result.shape[0])))\n",
        "df_result = df_result.set_index('No')\n",
        "\n",
        "del df_result.index.name\n",
        "\n",
        "nama_file = 'drive/My Drive/Deteksi fraud/hasil/ROS/UCSD/testing_balanced/result.csv'\n",
        "\n",
        "df_result.to_csv(nama_file, sep=';',index=False)\n",
        "\n",
        "df_result"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Akurasi</th>\n",
              "      <th>Sensitivity</th>\n",
              "      <th>Specifity</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.719057</td>\n",
              "      <td>0.706970</td>\n",
              "      <td>0.805572</td>\n",
              "      <td>0.962998</td>\n",
              "      <td>0.706970</td>\n",
              "      <td>0.815358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.733819</td>\n",
              "      <td>0.725635</td>\n",
              "      <td>0.792397</td>\n",
              "      <td>0.961564</td>\n",
              "      <td>0.725635</td>\n",
              "      <td>0.827104</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Akurasi  Sensitivity  Specifity  precision    recall  f1_score\n",
              "0  0.719057     0.706970   0.805572   0.962998  0.706970  0.815358\n",
              "1  0.733819     0.725635   0.792397   0.961564  0.725635  0.827104"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6aqw9APQU_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNmG2NEW3Ocm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dot_data = StringIO()  \n",
        "# tree.export_graphviz(clf.estimators_[8], out_file=dot_data,  \n",
        "#                          feature_names=X_new.columns)  \n",
        "# graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "# Image(graph.create_png())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HamwwIc_3Ocn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dot_data = StringIO()  \n",
        "# tree.export_graphviz(clf_DT,out_file=dot_data,feature_names=X_new.columns)  \n",
        "# graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "# Image(graph.create_png())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckRY0S_iPwu2",
        "colab_type": "text"
      },
      "source": [
        "---------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B3TKIyBPwrk",
        "colab_type": "text"
      },
      "source": [
        "## Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1ijvoao3Ocp",
        "colab_type": "code",
        "outputId": "c1ac1f34-9e26-41fa-cf9d-55b9481113f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        }
      },
      "source": [
        "print(__doc__)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from time import time\n",
        "from scipy.stats import randint as sp_randint\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# get some data\n",
        "digits = load_digits()\n",
        "X, y = digits.data, digits.target\n",
        "\n",
        "# build a classifier\n",
        "clf = RandomForestClassifier(random_state=1)\n",
        "\n",
        "\n",
        "# Utility function to report best scores\n",
        "def report(results, n_top=3):\n",
        "    for i in range(1, n_top + 1):\n",
        "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
        "        for candidate in candidates:\n",
        "            print(\"Model with rank: {0}\".format(i))\n",
        "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
        "                  results['mean_test_score'][candidate],\n",
        "                  results['std_test_score'][candidate]))\n",
        "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
        "            print(\"\")\n",
        "\n",
        "\n",
        "# specify parameters and distributions to sample from\n",
        "param_dist = {\n",
        "#               \"max_depth\": [5,9,11,15 ],\n",
        "              'n_estimators' : [10,25,50,75,100],\n",
        "               \"max_features\": ['sqrt','log2',None],\n",
        "#               \"min_samples_split\": sp_randint(2, 11),\n",
        "#               \"bootstrap\": [True, False],\n",
        "#               \"criterion\": [\"gini\", \"entropy\"]\n",
        "             }\n",
        "\n",
        "# run randomized search\n",
        "n_iter_search = 20\n",
        "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
        "                                   n_iter=n_iter_search, cv=5, iid=False,random_state=1)\n",
        "\n",
        "start = time()\n",
        "random_search.fit(X_new, y_new)\n",
        "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
        "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
        "report(random_search.cv_results_)\n",
        "\n",
        "# use a full grid over all parameters\n",
        "param_grid = {\n",
        "#               \"max_depth\": [5,9,11,15 ],\n",
        "              'n_estimators' : [10,25,50,75,100],\n",
        "               \"max_features\": ['sqrt','log2',None],\n",
        "#               \"min_samples_split\": [2, 3, 10],\n",
        "#               \"bootstrap\": [True, False],\n",
        "#               \"criterion\": [\"gini\", \"entropy\"]\n",
        "             }\n",
        "\n",
        "# run grid search\n",
        "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5, iid=False)\n",
        "start = time()\n",
        "grid_search.fit(X_new, y_new)\n",
        "\n",
        "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
        "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
        "report(grid_search.cv_results_)"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Automatically created module for IPython interactive environment\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 15 is smaller than n_iter=20. Running 15 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "RandomizedSearchCV took 11.21 seconds for 20 candidates parameter settings.\n",
            "Model with rank: 1\n",
            "Mean validation score: 0.748 (std: 0.022)\n",
            "Parameters: {'n_estimators': 50, 'max_features': 'sqrt'}\n",
            "\n",
            "Model with rank: 1\n",
            "Mean validation score: 0.748 (std: 0.022)\n",
            "Parameters: {'n_estimators': 50, 'max_features': 'log2'}\n",
            "\n",
            "Model with rank: 3\n",
            "Mean validation score: 0.748 (std: 0.013)\n",
            "Parameters: {'n_estimators': 100, 'max_features': 'sqrt'}\n",
            "\n",
            "Model with rank: 3\n",
            "Mean validation score: 0.748 (std: 0.013)\n",
            "Parameters: {'n_estimators': 100, 'max_features': 'log2'}\n",
            "\n",
            "GridSearchCV took 11.45 seconds for 15 candidate parameter settings.\n",
            "Model with rank: 1\n",
            "Mean validation score: 0.748 (std: 0.022)\n",
            "Parameters: {'max_features': 'sqrt', 'n_estimators': 50}\n",
            "\n",
            "Model with rank: 1\n",
            "Mean validation score: 0.748 (std: 0.022)\n",
            "Parameters: {'max_features': 'log2', 'n_estimators': 50}\n",
            "\n",
            "Model with rank: 3\n",
            "Mean validation score: 0.748 (std: 0.013)\n",
            "Parameters: {'max_features': 'sqrt', 'n_estimators': 100}\n",
            "\n",
            "Model with rank: 3\n",
            "Mean validation score: 0.748 (std: 0.013)\n",
            "Parameters: {'max_features': 'log2', 'n_estimators': 100}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_Ugm7bP3Ocq",
        "colab_type": "code",
        "outputId": "f87dd995-ac0d-40a4-c519-7bb136151603",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        }
      },
      "source": [
        "print(__doc__)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from time import time\n",
        "from scipy.stats import randint as sp_randint\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# get some data\n",
        "digits = load_digits()\n",
        "X, y = digits.data, digits.target\n",
        "\n",
        "# build a classifier\n",
        "clf = GradientBoostingClassifier(random_state=1)\n",
        "\n",
        "\n",
        "# Utility function to report best scores\n",
        "def report(results, n_top=3):\n",
        "    for i in range(1, n_top + 1):\n",
        "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
        "        for candidate in candidates:\n",
        "            print(\"Model with rank: {0}\".format(i))\n",
        "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
        "                  results['mean_test_score'][candidate],\n",
        "                  results['std_test_score'][candidate]))\n",
        "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
        "            print(\"\")\n",
        "\n",
        "\n",
        "# specify parameters and distributions to sample from\n",
        "param_dist = {\"max_depth\": [3,5,9 ],\n",
        "              'n_estimators' : [10,25,50,75,100],\n",
        "#               \"max_features\": sp_randint(1, 11),\n",
        "#               \"min_samples_split\": sp_randint(2, 11),\n",
        "#               \"bootstrap\": [True, False],\n",
        "#               \"criterion\": [\"gini\", \"entropy\"]\n",
        "             }\n",
        "\n",
        "# run randomized search\n",
        "n_iter_search = 20\n",
        "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
        "                                   n_iter=n_iter_search, cv=5, iid=False,random_state=1)\n",
        "\n",
        "start = time()\n",
        "random_search.fit(X_new, y_new)\n",
        "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
        "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
        "report(random_search.cv_results_)\n",
        "\n",
        "# use a full grid over all parameters\n",
        "param_grid = {\"max_depth\": [3,5,9],\n",
        "              'n_estimators' : [10,25,50,75,100],\n",
        "#               \"max_features\": [1, 3, 10],\n",
        "#               \"min_samples_split\": [2, 3, 10],\n",
        "#               \"bootstrap\": [True, False],\n",
        "#               \"criterion\": [\"gini\", \"entropy\"]\n",
        "             }\n",
        "\n",
        "# run grid search\n",
        "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5, iid=False)\n",
        "start = time()\n",
        "grid_search.fit(X_new, y_new)\n",
        "\n",
        "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
        "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
        "report(grid_search.cv_results_)"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Automatically created module for IPython interactive environment\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 15 is smaller than n_iter=20. Running 15 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "RandomizedSearchCV took 18.02 seconds for 20 candidates parameter settings.\n",
            "Model with rank: 1\n",
            "Mean validation score: 0.748 (std: 0.010)\n",
            "Parameters: {'n_estimators': 100, 'max_depth': 9}\n",
            "\n",
            "Model with rank: 2\n",
            "Mean validation score: 0.747 (std: 0.016)\n",
            "Parameters: {'n_estimators': 75, 'max_depth': 9}\n",
            "\n",
            "Model with rank: 3\n",
            "Mean validation score: 0.738 (std: 0.012)\n",
            "Parameters: {'n_estimators': 50, 'max_depth': 9}\n",
            "\n",
            "GridSearchCV took 18.10 seconds for 15 candidate parameter settings.\n",
            "Model with rank: 1\n",
            "Mean validation score: 0.748 (std: 0.010)\n",
            "Parameters: {'max_depth': 9, 'n_estimators': 100}\n",
            "\n",
            "Model with rank: 2\n",
            "Mean validation score: 0.747 (std: 0.016)\n",
            "Parameters: {'max_depth': 9, 'n_estimators': 75}\n",
            "\n",
            "Model with rank: 3\n",
            "Mean validation score: 0.738 (std: 0.012)\n",
            "Parameters: {'max_depth': 9, 'n_estimators': 50}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}