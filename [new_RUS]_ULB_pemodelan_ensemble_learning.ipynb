{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[new_RUS] ULB_pemodelan_ensemble_learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azizeko29/new_deteksi_fraud/blob/master/%5Bnew_RUS%5D_ULB_pemodelan_ensemble_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "qhorwCS90pU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "# import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "import math\n",
        "import collections\n",
        "import time\n",
        "from scipy import stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "JVakcQRs0pVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %matplotlib inline\n",
        "# from IPython.display import display\n",
        "# from sklearn import metrics\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.metrics import mean_squared_error\n",
        "# from statistics import stdev\n",
        "\n",
        "from sklearn import tree\n",
        "\n",
        "from IPython.display import Image  \n",
        "from sklearn.externals.six import StringIO  \n",
        "import pydotplus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2iQeEbs0pVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MfeBiCN0pVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def confussion_matrik(actual,predict):\n",
        "    TP,FP,FN,TN = 0,0,0,0\n",
        "    for i,val in enumerate(actual):\n",
        "        if val == 0:\n",
        "            if val == predict[i]:\n",
        "                TN += 1\n",
        "            else:\n",
        "                FP += 1\n",
        "        if val == 1:\n",
        "            if val == predict[i]:\n",
        "                TP += 1\n",
        "            else:\n",
        "                FN += 1\n",
        "    return TP,FP,FN,TN\n",
        " \n",
        "def acc_sens_spec(actual,predict):\n",
        "    TP,FP,FN,TN = confussion_matrik(actual,predict)\n",
        "# akurasi\n",
        "    if (TP+FP+FN+TN) == 0 :\n",
        "        accuracy = 0 \n",
        "    else :\n",
        "        accuracy = (TP+TN)/(TP+FP+FN+TN)\n",
        "        \n",
        "# sensitivity\n",
        "    if (TP+FN) == 0 :\n",
        "        sensitivity = 0\n",
        "    else :\n",
        "        sensitivity = TP/(TP+FN)\n",
        "        \n",
        "# specifity    \n",
        "    if (TN +FP) == 0 :\n",
        "        specifity = 0\n",
        "    else :\n",
        "        specifity = TN/(TN +FP)\n",
        "        \n",
        "# precision\n",
        "    if (TP+FP) == 0 :\n",
        "        precision = 0\n",
        "    else :\n",
        "        precision = TP/(TP+FP)\n",
        "\n",
        "# recall\n",
        "    recall = sensitivity\n",
        "\n",
        "# f1_score\n",
        "    if (precision+recall) == 0 :\n",
        "        f1_score = 0\n",
        "    else :\n",
        "        f1_score = 2*((precision*recall)/(precision+recall))  \n",
        "    \n",
        "    return accuracy,sensitivity,specifity,precision,recall,f1_score\n",
        "\n",
        "# Calculate accuracy percentage\n",
        "def accuracy_metric(actual, predicted):\n",
        "    #how many correct predictions?\n",
        "    correct = 0\n",
        "    #for each actual label\n",
        "    for i in range(len(actual)):\n",
        "        #if actual matches predicted label\n",
        "        if actual[i] == predicted[i]:\n",
        "            #add 1 to the correct iterator\n",
        "            correct += 1\n",
        "    #return percentage of predictions that were correct\n",
        "    return correct / float(len(actual)) * 100.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx6bm6hU0pVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# confussion_matrik(y,pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY_TWVIp0pVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# accuracy,sensitivity,specifity = acc_sens_spec(y,pred)\n",
        "# print('acc',accuracy)\n",
        "# print('sens',sensitivity)\n",
        "# print('spec',specifity)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "F0-pV4LQ0pVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# accuracy_metric(y,RF.predict(X))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGWI9BJv0pVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cross_val_split(X,fold=2,seed=0):\n",
        "    np.random.seed(seed)\n",
        "    n_folds= fold\n",
        "    size = X.shape[0]/n_folds\n",
        "    X_idx = list(range(X.shape[0]))\n",
        "    folds_data= []\n",
        "    for i in range(n_folds):\n",
        "#         print(X_idx)\n",
        "        random_idx = list(np.random.choice(X_idx,int(size),replace=False))\n",
        "#         print(random_idx)\n",
        "        X_idx = [idx for idx in X_idx if idx not in random_idx]\n",
        "#         print(X_idx)\n",
        "\n",
        "        folds_data.append(random_idx)\n",
        "#         print(\"--\")\n",
        "    return folds_data\n",
        "\n",
        "def kfold_cross_validation(model,X,y, n_fold=2, n_seed=0):\n",
        "    folds = cross_val_split(X,fold=n_fold,seed=n_seed)\n",
        "    fold_result =[]\n",
        "    for i in range(len(folds)):\n",
        "    #     print(i)\n",
        "        train = []\n",
        "        for j in range(len(folds)):\n",
        "            if j != i:\n",
        "                train = train + folds[j]\n",
        "        test = folds[i]\n",
        "\n",
        "        X_train = X.iloc[train,:].reset_index(drop=True)\n",
        "        y_train = y[train].reset_index(drop=True)\n",
        "\n",
        "        X_test = X.iloc[test,:].reset_index(drop=True)\n",
        "        y_test = y[test].reset_index(drop=True)\n",
        "\n",
        "\n",
        "        t0 = time.time()\n",
        "        model.fit(X_train, y_train)\n",
        "        t1 = time.time()\n",
        "        waktu = t1 - t0\n",
        "\n",
        "        predict = model.predict(X_test)\n",
        "        accuracy,sensitivity,specifity,precision,recall,f1_score = acc_sens_spec(y_test,predict)\n",
        "\n",
        "        result = [accuracy,sensitivity,specifity,precision,recall,f1_score,waktu]\n",
        "        fold_result.append(result)\n",
        "        \n",
        "    return fold_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Is3g1hNE2Oa9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testing(model,X_test,y_test):\n",
        "    result_ = []\n",
        "\n",
        "#       t0 = time.time()\n",
        "#       model.fit(X_train, y_train)\n",
        "#       t1 = time.time()\n",
        "#       waktu = t1 - t0\n",
        "    predict = model.predict(X_test)\n",
        "    accuracy,sensitivity,specifity,precision,recall,f1_score = acc_sens_spec(y_test,predict)\n",
        "\n",
        "    result = [accuracy,sensitivity,specifity,precision,recall,f1_score]\n",
        "        \n",
        "    result_.append(result)\n",
        "        \n",
        "    return result_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUxofECh0pVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.decomposition import PCA\n",
        "# import pylab as pl\n",
        "# def plot_this(X_rs,y_rs,method):\n",
        "#   # Use principal component to condense the 10 features to 2 features\n",
        "#   pca = PCA(n_components=2).fit(X_rs)\n",
        "#   pca_2d = pca.transform(X_rs)\n",
        "#   # Assign colors\n",
        "#   for i in range(0, pca_2d.shape[0]):\n",
        "#     if y_rs[i] == 0:\n",
        "#       c1 = pl.scatter(pca_2d[i,0],pca_2d[i,1],c='r', marker='o')\n",
        "#     elif y_rs[i] == 1:\n",
        "#       c2 = pl.scatter(pca_2d[i,0],pca_2d[i,1],c='g', marker='*')  \n",
        "#   pl.legend([c1, c2], ['Class 1', 'Class 2'])\n",
        "#   pl.title(method)\n",
        "#   pl.axis([-4, 5, -4, 4])  # x axis (-4,5), y axis (-4,4)\n",
        "#   pl.show()\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_KBJ2Rm0pVq",
        "colab_type": "text"
      },
      "source": [
        "## ---------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNk8CXpR0pVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ##read data\n",
        "\n",
        "# df = pd.read_csv('data/creditcard_ulb.csv',sep=\",\")\n",
        "# # df = pd.read_csv('data/sample_data.csv',sep=\",\")\n",
        "\n",
        "# df0 = df.copy()\n",
        "# df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LwxuDeaAqRF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "19d3b836-1956-4fa2-b931-f73d080edf45"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQRHF-uwA7s3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ##read data\n",
        "\n",
        "read_df = pd.read_csv('drive/My Drive/Deteksi fraud/data/creditcard_ulb.csv',sep=\",\")\n",
        "# # df = pd.read_csv('data/sample_data.csv',sep=\",\")\n",
        "\n",
        "# df0 = df.copy()\n",
        "# df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2n8i4xh1jqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Code to read csv file into Colaboratory:\n",
        "# !pip install -U -q PyDrive\n",
        "# from pydrive.auth import GoogleAuth\n",
        "# from pydrive.drive import GoogleDrive\n",
        "# from google.colab import auth\n",
        "# from oauth2client.client import GoogleCredentials\n",
        "# # Authenticate and create the PyDrive client.\n",
        "# auth.authenticate_user()\n",
        "# gauth = GoogleAuth()\n",
        "# gauth.credentials = GoogleCredentials.get_application_default()\n",
        "# drive = GoogleDrive(gauth)\n",
        "\n",
        "# link = 'https://drive.google.com/open?id=1PqCaaZwbyxrFdhLLPFB0TM9Z4jcP7LPo' # The shareable link\n",
        "\n",
        "# fluff, id = link.split('=')\n",
        "# print (id) # Verify that you have everything after '='\n",
        "\n",
        "# downloaded = drive.CreateFile({'id':id}) \n",
        "# downloaded.GetContentFile('creditcard_ulb.csv')  \n",
        "# read_df = pd.read_csv('creditcard_ulb.csv')\n",
        "# # Dataset is now stored in a Pandas Dataframe\n",
        "# # df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asAMzLKA1wby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = read_df.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3M3tn8i0pVy",
        "colab_type": "code",
        "outputId": "3b1797c1-2d70-40f7-c73e-117ffcc29c69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWjnAx8s0pV4",
        "colab_type": "code",
        "outputId": "4a2036b7-3d11-43c9-c162-9bbe16a58ddc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>284802</th>\n",
              "      <td>172786.0</td>\n",
              "      <td>-11.881118</td>\n",
              "      <td>10.071785</td>\n",
              "      <td>-9.834783</td>\n",
              "      <td>-2.066656</td>\n",
              "      <td>-5.364473</td>\n",
              "      <td>-2.606837</td>\n",
              "      <td>-4.918215</td>\n",
              "      <td>7.305334</td>\n",
              "      <td>1.914428</td>\n",
              "      <td>4.356170</td>\n",
              "      <td>-1.593105</td>\n",
              "      <td>2.711941</td>\n",
              "      <td>-0.689256</td>\n",
              "      <td>4.626942</td>\n",
              "      <td>-0.924459</td>\n",
              "      <td>1.107641</td>\n",
              "      <td>1.991691</td>\n",
              "      <td>0.510632</td>\n",
              "      <td>-0.682920</td>\n",
              "      <td>1.475829</td>\n",
              "      <td>0.213454</td>\n",
              "      <td>0.111864</td>\n",
              "      <td>1.014480</td>\n",
              "      <td>-0.509348</td>\n",
              "      <td>1.436807</td>\n",
              "      <td>0.250034</td>\n",
              "      <td>0.943651</td>\n",
              "      <td>0.823731</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284803</th>\n",
              "      <td>172787.0</td>\n",
              "      <td>-0.732789</td>\n",
              "      <td>-0.055080</td>\n",
              "      <td>2.035030</td>\n",
              "      <td>-0.738589</td>\n",
              "      <td>0.868229</td>\n",
              "      <td>1.058415</td>\n",
              "      <td>0.024330</td>\n",
              "      <td>0.294869</td>\n",
              "      <td>0.584800</td>\n",
              "      <td>-0.975926</td>\n",
              "      <td>-0.150189</td>\n",
              "      <td>0.915802</td>\n",
              "      <td>1.214756</td>\n",
              "      <td>-0.675143</td>\n",
              "      <td>1.164931</td>\n",
              "      <td>-0.711757</td>\n",
              "      <td>-0.025693</td>\n",
              "      <td>-1.221179</td>\n",
              "      <td>-1.545556</td>\n",
              "      <td>0.059616</td>\n",
              "      <td>0.214205</td>\n",
              "      <td>0.924384</td>\n",
              "      <td>0.012463</td>\n",
              "      <td>-1.016226</td>\n",
              "      <td>-0.606624</td>\n",
              "      <td>-0.395255</td>\n",
              "      <td>0.068472</td>\n",
              "      <td>-0.053527</td>\n",
              "      <td>24.79</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284804</th>\n",
              "      <td>172788.0</td>\n",
              "      <td>1.919565</td>\n",
              "      <td>-0.301254</td>\n",
              "      <td>-3.249640</td>\n",
              "      <td>-0.557828</td>\n",
              "      <td>2.630515</td>\n",
              "      <td>3.031260</td>\n",
              "      <td>-0.296827</td>\n",
              "      <td>0.708417</td>\n",
              "      <td>0.432454</td>\n",
              "      <td>-0.484782</td>\n",
              "      <td>0.411614</td>\n",
              "      <td>0.063119</td>\n",
              "      <td>-0.183699</td>\n",
              "      <td>-0.510602</td>\n",
              "      <td>1.329284</td>\n",
              "      <td>0.140716</td>\n",
              "      <td>0.313502</td>\n",
              "      <td>0.395652</td>\n",
              "      <td>-0.577252</td>\n",
              "      <td>0.001396</td>\n",
              "      <td>0.232045</td>\n",
              "      <td>0.578229</td>\n",
              "      <td>-0.037501</td>\n",
              "      <td>0.640134</td>\n",
              "      <td>0.265745</td>\n",
              "      <td>-0.087371</td>\n",
              "      <td>0.004455</td>\n",
              "      <td>-0.026561</td>\n",
              "      <td>67.88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284805</th>\n",
              "      <td>172788.0</td>\n",
              "      <td>-0.240440</td>\n",
              "      <td>0.530483</td>\n",
              "      <td>0.702510</td>\n",
              "      <td>0.689799</td>\n",
              "      <td>-0.377961</td>\n",
              "      <td>0.623708</td>\n",
              "      <td>-0.686180</td>\n",
              "      <td>0.679145</td>\n",
              "      <td>0.392087</td>\n",
              "      <td>-0.399126</td>\n",
              "      <td>-1.933849</td>\n",
              "      <td>-0.962886</td>\n",
              "      <td>-1.042082</td>\n",
              "      <td>0.449624</td>\n",
              "      <td>1.962563</td>\n",
              "      <td>-0.608577</td>\n",
              "      <td>0.509928</td>\n",
              "      <td>1.113981</td>\n",
              "      <td>2.897849</td>\n",
              "      <td>0.127434</td>\n",
              "      <td>0.265245</td>\n",
              "      <td>0.800049</td>\n",
              "      <td>-0.163298</td>\n",
              "      <td>0.123205</td>\n",
              "      <td>-0.569159</td>\n",
              "      <td>0.546668</td>\n",
              "      <td>0.108821</td>\n",
              "      <td>0.104533</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284806</th>\n",
              "      <td>172792.0</td>\n",
              "      <td>-0.533413</td>\n",
              "      <td>-0.189733</td>\n",
              "      <td>0.703337</td>\n",
              "      <td>-0.506271</td>\n",
              "      <td>-0.012546</td>\n",
              "      <td>-0.649617</td>\n",
              "      <td>1.577006</td>\n",
              "      <td>-0.414650</td>\n",
              "      <td>0.486180</td>\n",
              "      <td>-0.915427</td>\n",
              "      <td>-1.040458</td>\n",
              "      <td>-0.031513</td>\n",
              "      <td>-0.188093</td>\n",
              "      <td>-0.084316</td>\n",
              "      <td>0.041333</td>\n",
              "      <td>-0.302620</td>\n",
              "      <td>-0.660377</td>\n",
              "      <td>0.167430</td>\n",
              "      <td>-0.256117</td>\n",
              "      <td>0.382948</td>\n",
              "      <td>0.261057</td>\n",
              "      <td>0.643078</td>\n",
              "      <td>0.376777</td>\n",
              "      <td>0.008797</td>\n",
              "      <td>-0.473649</td>\n",
              "      <td>-0.818267</td>\n",
              "      <td>-0.002415</td>\n",
              "      <td>0.013649</td>\n",
              "      <td>217.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Time         V1         V2  ...       V28  Amount  Class\n",
              "284802  172786.0 -11.881118  10.071785  ...  0.823731    0.77      0\n",
              "284803  172787.0  -0.732789  -0.055080  ... -0.053527   24.79      0\n",
              "284804  172788.0   1.919565  -0.301254  ... -0.026561   67.88      0\n",
              "284805  172788.0  -0.240440   0.530483  ...  0.104533   10.00      0\n",
              "284806  172792.0  -0.533413  -0.189733  ...  0.013649  217.00      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jN6s3PK0pV-",
        "colab_type": "code",
        "outputId": "106b6d3b-7ba4-4efe-f120-c5c47659d26d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "df['Class'].value_counts()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    284315\n",
              "1       492\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1KQqHE40pWD",
        "colab_type": "code",
        "outputId": "8f0737b4-ee90-4794-e738-e45f7ec198aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "plt.figure(1,figsize=(5, 5), dpi=80)\n",
        "plt.grid(color='b', linestyle='-', linewidth=0.2)\n",
        "plt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14)\n",
        "sns.countplot('Class', data=df,palette='Set2')\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f14cfa42f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAGLCAYAAADksLTTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqZR2kcj0pWH",
        "colab_type": "code",
        "outputId": "d1431b7d-b773-4314-f9cb-dcfc3da12d19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "count = 0\n",
        "for a in df.columns[1:]:\n",
        "    if df[a].isnull().sum() > 0 :\n",
        "#         print(a)\n",
        "        count+=1\n",
        "count"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipCzb3z1SdQT",
        "colab_type": "code",
        "outputId": "5f86b874-4cbc-446e-c725-e2ee7873cf9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "df['Class'].value_counts()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    284315\n",
              "1       492\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDtpAjOgTGCX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class'].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ0RAj-h0pWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2, stratify=y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_ShPAU4EGLv",
        "colab_type": "code",
        "outputId": "25bbb5e1-5001-4d42-be33-1d35cdbcef43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>67718</th>\n",
              "      <td>52669.0</td>\n",
              "      <td>-1.044875</td>\n",
              "      <td>-0.699877</td>\n",
              "      <td>2.383771</td>\n",
              "      <td>0.462870</td>\n",
              "      <td>-0.523350</td>\n",
              "      <td>-0.484606</td>\n",
              "      <td>-0.782931</td>\n",
              "      <td>0.160622</td>\n",
              "      <td>-1.059381</td>\n",
              "      <td>0.666156</td>\n",
              "      <td>-0.591895</td>\n",
              "      <td>0.378854</td>\n",
              "      <td>2.008465</td>\n",
              "      <td>-0.634986</td>\n",
              "      <td>1.418612</td>\n",
              "      <td>-1.196899</td>\n",
              "      <td>-0.341566</td>\n",
              "      <td>2.081873</td>\n",
              "      <td>-0.795839</td>\n",
              "      <td>0.267347</td>\n",
              "      <td>0.102301</td>\n",
              "      <td>0.625710</td>\n",
              "      <td>0.285710</td>\n",
              "      <td>0.390592</td>\n",
              "      <td>-0.443462</td>\n",
              "      <td>-0.238541</td>\n",
              "      <td>0.448415</td>\n",
              "      <td>0.273184</td>\n",
              "      <td>90.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99134</th>\n",
              "      <td>66981.0</td>\n",
              "      <td>-0.105756</td>\n",
              "      <td>1.055263</td>\n",
              "      <td>0.219036</td>\n",
              "      <td>0.972113</td>\n",
              "      <td>0.544316</td>\n",
              "      <td>-1.205159</td>\n",
              "      <td>0.996226</td>\n",
              "      <td>-0.342528</td>\n",
              "      <td>-0.555430</td>\n",
              "      <td>0.305929</td>\n",
              "      <td>-0.402451</td>\n",
              "      <td>0.358783</td>\n",
              "      <td>0.727030</td>\n",
              "      <td>0.308077</td>\n",
              "      <td>0.605273</td>\n",
              "      <td>-0.596082</td>\n",
              "      <td>-0.201596</td>\n",
              "      <td>-0.212436</td>\n",
              "      <td>0.397815</td>\n",
              "      <td>0.061089</td>\n",
              "      <td>0.149714</td>\n",
              "      <td>0.680987</td>\n",
              "      <td>0.163366</td>\n",
              "      <td>0.412736</td>\n",
              "      <td>-0.658454</td>\n",
              "      <td>-0.424248</td>\n",
              "      <td>0.326754</td>\n",
              "      <td>0.220772</td>\n",
              "      <td>2.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255988</th>\n",
              "      <td>157487.0</td>\n",
              "      <td>2.273034</td>\n",
              "      <td>-0.620167</td>\n",
              "      <td>-1.579732</td>\n",
              "      <td>-1.038778</td>\n",
              "      <td>-0.195400</td>\n",
              "      <td>-1.021584</td>\n",
              "      <td>-0.241990</td>\n",
              "      <td>-0.453477</td>\n",
              "      <td>-0.649705</td>\n",
              "      <td>0.849121</td>\n",
              "      <td>-1.056267</td>\n",
              "      <td>-0.269228</td>\n",
              "      <td>1.409078</td>\n",
              "      <td>-0.228375</td>\n",
              "      <td>0.256648</td>\n",
              "      <td>1.030782</td>\n",
              "      <td>-0.164283</td>\n",
              "      <td>-1.212026</td>\n",
              "      <td>0.675735</td>\n",
              "      <td>0.059748</td>\n",
              "      <td>0.400569</td>\n",
              "      <td>1.235467</td>\n",
              "      <td>-0.112693</td>\n",
              "      <td>-0.563243</td>\n",
              "      <td>0.332715</td>\n",
              "      <td>0.105684</td>\n",
              "      <td>-0.032988</td>\n",
              "      <td>-0.070058</td>\n",
              "      <td>15.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121848</th>\n",
              "      <td>76343.0</td>\n",
              "      <td>-0.868089</td>\n",
              "      <td>-0.127889</td>\n",
              "      <td>1.473924</td>\n",
              "      <td>-1.124669</td>\n",
              "      <td>-1.904013</td>\n",
              "      <td>1.163006</td>\n",
              "      <td>-0.283742</td>\n",
              "      <td>0.746531</td>\n",
              "      <td>-0.736264</td>\n",
              "      <td>-0.175059</td>\n",
              "      <td>0.401805</td>\n",
              "      <td>-0.213943</td>\n",
              "      <td>-0.774657</td>\n",
              "      <td>-0.389873</td>\n",
              "      <td>-1.238179</td>\n",
              "      <td>0.851705</td>\n",
              "      <td>0.798677</td>\n",
              "      <td>-1.065141</td>\n",
              "      <td>1.117206</td>\n",
              "      <td>-0.052033</td>\n",
              "      <td>0.176907</td>\n",
              "      <td>0.469763</td>\n",
              "      <td>0.029259</td>\n",
              "      <td>-0.303608</td>\n",
              "      <td>-0.126885</td>\n",
              "      <td>-0.257276</td>\n",
              "      <td>-0.073542</td>\n",
              "      <td>-0.063614</td>\n",
              "      <td>189.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274029</th>\n",
              "      <td>165822.0</td>\n",
              "      <td>-1.240829</td>\n",
              "      <td>-0.395491</td>\n",
              "      <td>1.958589</td>\n",
              "      <td>-0.047792</td>\n",
              "      <td>0.597116</td>\n",
              "      <td>-0.861073</td>\n",
              "      <td>-0.174849</td>\n",
              "      <td>0.156320</td>\n",
              "      <td>0.198213</td>\n",
              "      <td>-0.808267</td>\n",
              "      <td>-0.964026</td>\n",
              "      <td>-0.429859</td>\n",
              "      <td>-0.809422</td>\n",
              "      <td>0.190108</td>\n",
              "      <td>1.242464</td>\n",
              "      <td>-0.312181</td>\n",
              "      <td>0.034655</td>\n",
              "      <td>0.026180</td>\n",
              "      <td>1.173892</td>\n",
              "      <td>0.349427</td>\n",
              "      <td>-0.141820</td>\n",
              "      <td>-0.729206</td>\n",
              "      <td>0.066061</td>\n",
              "      <td>-0.130264</td>\n",
              "      <td>0.157839</td>\n",
              "      <td>-0.011302</td>\n",
              "      <td>0.015111</td>\n",
              "      <td>0.093282</td>\n",
              "      <td>39.95</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Time        V1        V2  ...       V27       V28  Amount\n",
              "67718    52669.0 -1.044875 -0.699877  ...  0.448415  0.273184   90.00\n",
              "99134    66981.0 -0.105756  1.055263  ...  0.326754  0.220772    2.69\n",
              "255988  157487.0  2.273034 -0.620167  ... -0.032988 -0.070058   15.00\n",
              "121848   76343.0 -0.868089 -0.127889  ... -0.073542 -0.063614  189.90\n",
              "274029  165822.0 -1.240829 -0.395491  ...  0.015111  0.093282   39.95\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOTrC4YZQ0Ly",
        "colab_type": "code",
        "outputId": "9cd5c6e3-244e-4f33-aac3-8956998b57c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(199364,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDiVLjRyRA2m",
        "colab_type": "code",
        "outputId": "689de231-90fb-470e-a2be-ddcf1e427506",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(85443,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsf34d-VRPpO",
        "colab_type": "code",
        "outputId": "bf0f746f-60ce-4897-ef5f-9779ecda409b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "y_test.value_counts()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    85295\n",
              "1      148\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TL_nFQHQRPsU",
        "colab_type": "code",
        "outputId": "7e2bedca-21fe-43c0-e8b8-974304452cf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "y_train.value_counts()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    199020\n",
              "1       344\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJXzNnm8Tpyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = X_train.copy()\n",
        "df_train['Class'] = y_train.copy()\n",
        "df_train.to_csv('drive/My Drive/Deteksi fraud/data/ULB_preprocessing_train.csv',sep=';',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh9OzBssVa-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test = X_test.copy()\n",
        "df_test['Class'] = y_test.copy()\n",
        "df_test.to_csv('drive/My Drive/Deteksi fraud/data/ULB_preprocessing_test.csv',sep=';',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkvDxKty0pWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Since most of our data has already been scaled we should scale the columns that are left to scale (Amount and Time)\n",
        "# from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
        "\n",
        "# # RobustScaler is less prone to outliers.\n",
        "\n",
        "# std_scaler = StandardScaler()\n",
        "# rob_scaler = RobustScaler()\n",
        "# minmax_scaler = MinMaxScaler()\n",
        "\n",
        "# # df['scaled_amount'] = rob_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\n",
        "# # df['scaled_time'] = rob_scaler.fit_transform(df['Time'].values.reshape(-1,1))\n",
        "\n",
        "# df['scaled_amount'] = minmax_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\n",
        "# df['scaled_time'] = minmax_scaler.fit_transform(df['Time'].values.reshape(-1,1))\n",
        "\n",
        "# df.drop(['Time','Amount'], axis=1, inplace=True)\n",
        "\n",
        "# scaled_amount = df['scaled_amount']\n",
        "# scaled_time = df['scaled_time']\n",
        "\n",
        "# df.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\n",
        "# df.insert(0, 'scaled_amount', scaled_amount)\n",
        "# df.insert(1, 'scaled_time', scaled_time)\n",
        "\n",
        "# # Amount and Time are Scaled!\n",
        "\n",
        "# df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUVZsMIB0pWR",
        "colab_type": "code",
        "outputId": "3c304244-1a17-4579-b6e0-35d291c76f8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "# Since our classes are highly skewed we should make them equivalent in order to have a normal distribution of the classes.\n",
        "\n",
        "# Lets shuffle the data before creating the subsamples\n",
        "df_copy = df_train.copy()\n",
        "# df_copy = df_copy.sample(frac=1)\n",
        "\n",
        "fraud_df = df_copy.loc[df_copy['Class'] == 1]\n",
        "# non_fraud_df = df_copy.loc[df['Class'] == 0][:344]\n",
        "non_fraud_df = df_copy.loc[df_copy['Class'] == 0].sample(n=344,random_state=1)\n",
        "\n",
        "normal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n",
        "\n",
        "# Shuffle dataframe rows\n",
        "df_new = normal_distributed_df.sample(frac=1, random_state=1)\n",
        "df_new = df_new.reset_index()\n",
        "df_new = df_new.drop('index', axis=1)\n",
        "df_new.head()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>139767.0</td>\n",
              "      <td>0.467992</td>\n",
              "      <td>1.100118</td>\n",
              "      <td>-5.607145</td>\n",
              "      <td>2.204714</td>\n",
              "      <td>-0.578539</td>\n",
              "      <td>-0.174200</td>\n",
              "      <td>-3.454201</td>\n",
              "      <td>1.102823</td>\n",
              "      <td>-1.065016</td>\n",
              "      <td>-5.416037</td>\n",
              "      <td>4.497929</td>\n",
              "      <td>-5.019610</td>\n",
              "      <td>-1.019691</td>\n",
              "      <td>-7.914989</td>\n",
              "      <td>0.669648</td>\n",
              "      <td>-4.472014</td>\n",
              "      <td>-5.856998</td>\n",
              "      <td>-2.243178</td>\n",
              "      <td>-0.173814</td>\n",
              "      <td>0.589575</td>\n",
              "      <td>0.983481</td>\n",
              "      <td>0.899876</td>\n",
              "      <td>-0.285103</td>\n",
              "      <td>-1.929717</td>\n",
              "      <td>0.319869</td>\n",
              "      <td>0.170636</td>\n",
              "      <td>0.851798</td>\n",
              "      <td>0.372098</td>\n",
              "      <td>120.54</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>70536.0</td>\n",
              "      <td>-2.271755</td>\n",
              "      <td>-0.457655</td>\n",
              "      <td>-2.589055</td>\n",
              "      <td>2.230778</td>\n",
              "      <td>-4.278983</td>\n",
              "      <td>0.388610</td>\n",
              "      <td>0.102485</td>\n",
              "      <td>0.813128</td>\n",
              "      <td>-1.092921</td>\n",
              "      <td>-5.032028</td>\n",
              "      <td>3.510348</td>\n",
              "      <td>-2.227398</td>\n",
              "      <td>0.656824</td>\n",
              "      <td>-5.199186</td>\n",
              "      <td>-0.128311</td>\n",
              "      <td>-3.943521</td>\n",
              "      <td>-3.820522</td>\n",
              "      <td>-0.570821</td>\n",
              "      <td>2.783383</td>\n",
              "      <td>2.285758</td>\n",
              "      <td>1.096342</td>\n",
              "      <td>0.658399</td>\n",
              "      <td>1.711676</td>\n",
              "      <td>0.333540</td>\n",
              "      <td>0.538591</td>\n",
              "      <td>-0.193529</td>\n",
              "      <td>0.258194</td>\n",
              "      <td>0.247269</td>\n",
              "      <td>824.83</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>130349.0</td>\n",
              "      <td>1.764965</td>\n",
              "      <td>-0.640638</td>\n",
              "      <td>-0.452079</td>\n",
              "      <td>0.121273</td>\n",
              "      <td>0.242557</td>\n",
              "      <td>1.935698</td>\n",
              "      <td>-1.005408</td>\n",
              "      <td>0.671404</td>\n",
              "      <td>1.133422</td>\n",
              "      <td>-0.203693</td>\n",
              "      <td>1.474416</td>\n",
              "      <td>1.725986</td>\n",
              "      <td>0.542809</td>\n",
              "      <td>-0.005425</td>\n",
              "      <td>0.827996</td>\n",
              "      <td>-0.928667</td>\n",
              "      <td>0.309578</td>\n",
              "      <td>-1.213858</td>\n",
              "      <td>-1.379076</td>\n",
              "      <td>-0.299957</td>\n",
              "      <td>0.351390</td>\n",
              "      <td>1.411035</td>\n",
              "      <td>0.187029</td>\n",
              "      <td>-1.643892</td>\n",
              "      <td>-0.381872</td>\n",
              "      <td>-0.086202</td>\n",
              "      <td>0.112130</td>\n",
              "      <td>-0.063010</td>\n",
              "      <td>11.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>51155.0</td>\n",
              "      <td>-11.205461</td>\n",
              "      <td>7.914633</td>\n",
              "      <td>-13.987752</td>\n",
              "      <td>4.333341</td>\n",
              "      <td>-8.484970</td>\n",
              "      <td>-3.506561</td>\n",
              "      <td>-8.935243</td>\n",
              "      <td>7.704449</td>\n",
              "      <td>-2.336584</td>\n",
              "      <td>-5.927359</td>\n",
              "      <td>2.470401</td>\n",
              "      <td>-5.788517</td>\n",
              "      <td>-0.391939</td>\n",
              "      <td>-6.527462</td>\n",
              "      <td>0.899859</td>\n",
              "      <td>-3.847293</td>\n",
              "      <td>-6.700637</td>\n",
              "      <td>-2.492616</td>\n",
              "      <td>0.469554</td>\n",
              "      <td>0.860912</td>\n",
              "      <td>0.942593</td>\n",
              "      <td>-0.987848</td>\n",
              "      <td>-0.279446</td>\n",
              "      <td>-0.027299</td>\n",
              "      <td>0.644344</td>\n",
              "      <td>-0.263078</td>\n",
              "      <td>1.084023</td>\n",
              "      <td>0.211933</td>\n",
              "      <td>99.99</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>78668.0</td>\n",
              "      <td>1.237688</td>\n",
              "      <td>0.360344</td>\n",
              "      <td>-0.287389</td>\n",
              "      <td>0.865929</td>\n",
              "      <td>0.496825</td>\n",
              "      <td>-0.187566</td>\n",
              "      <td>0.404371</td>\n",
              "      <td>-0.101166</td>\n",
              "      <td>-0.154733</td>\n",
              "      <td>-0.046287</td>\n",
              "      <td>-0.840872</td>\n",
              "      <td>0.021235</td>\n",
              "      <td>-0.071557</td>\n",
              "      <td>0.558838</td>\n",
              "      <td>1.070609</td>\n",
              "      <td>-0.097905</td>\n",
              "      <td>-0.350690</td>\n",
              "      <td>-0.829990</td>\n",
              "      <td>-0.141321</td>\n",
              "      <td>-0.131606</td>\n",
              "      <td>-0.373471</td>\n",
              "      <td>-1.101931</td>\n",
              "      <td>0.023660</td>\n",
              "      <td>-0.829145</td>\n",
              "      <td>0.492318</td>\n",
              "      <td>-0.614306</td>\n",
              "      <td>0.011220</td>\n",
              "      <td>0.012320</td>\n",
              "      <td>21.37</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Time         V1        V2         V3  ...       V27       V28  Amount  Class\n",
              "0  139767.0   0.467992  1.100118  -5.607145  ...  0.851798  0.372098  120.54      1\n",
              "1   70536.0  -2.271755 -0.457655  -2.589055  ...  0.258194  0.247269  824.83      1\n",
              "2  130349.0   1.764965 -0.640638  -0.452079  ...  0.112130 -0.063010   11.50      0\n",
              "3   51155.0 -11.205461  7.914633 -13.987752  ...  1.084023  0.211933   99.99      1\n",
              "4   78668.0   1.237688  0.360344  -0.287389  ...  0.011220  0.012320   21.37      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt8BRgQR0pWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hpwvc77C0pWa",
        "colab_type": "code",
        "outputId": "a46ac47f-a69d-4233-b739-e3cbe52af412",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "plt.figure(1,figsize=(5, 5), dpi=80)\n",
        "plt.grid(color='b', linestyle='-', linewidth=0.2)\n",
        "plt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14)\n",
        "sns.countplot('Class', data=df_new,palette='Set2')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f14cce0f780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAGLCAYAAAAvR5JoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJwi_WXQ0pWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX3HYPhb0pWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X = df.drop('Class', axis=1)\n",
        "# y = df['Class'].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caCPe2iv0pWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_new = df_new.drop('Class', axis=1)\n",
        "y_new = df_new['Class'].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgFBdJYI0pWy",
        "colab_type": "code",
        "outputId": "94882ec1-b9b0-42bb-ff1b-7f98790efe19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "y_new.value_counts()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    344\n",
              "0    344\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLN-D7aE0pW3",
        "colab_type": "code",
        "outputId": "0cabbb2e-4323-4aa1-bf72-9985670b89b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "X_new.columns"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
              "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
              "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s94LTp6MVet7",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2w12u1g0pW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbJzY3gx0pXH",
        "colab_type": "text"
      },
      "source": [
        "## K-folds\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M_uzJJ20pXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validasi_model (clf,X,y,kfolds):\n",
        "    CV_SKLearn = kfold_cross_validation(clf,X,y,n_fold=kfolds,n_seed=1)\n",
        "    df_result = pd.DataFrame(data= CV_SKLearn, columns=['Akurasi','Sensitivity','Specifity','precision','recall','f1_score','Waktu'])\n",
        "\n",
        "    df_result.insert(loc=0, column='No', value=list(range(1,df_result.shape[0]+1)))\n",
        "    df_result = df_result.set_index('No')\n",
        "\n",
        "    del df_result.index.name\n",
        "\n",
        "    df_result = df_result.append(df_result.describe()[1:2])\n",
        "    \n",
        "    return df_result\n",
        "# result_SKLearn = result_SKLearn.append('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5CyLZdw67e7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orHWLKtp0pXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Classifier Libraries\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "    \n",
        "clf_RF = RandomForestClassifier(random_state=1,n_estimators=10)\n",
        "clf_AB = AdaBoostClassifier(random_state=1,n_estimators=100)\n",
        "clf_B = BaggingClassifier(random_state=1,n_estimators=100)\n",
        "clf_ET = ExtraTreesClassifier(random_state=1,n_estimators=100)\n",
        "clf_GB = GradientBoostingClassifier(random_state=1,n_estimators=50)\n",
        "\n",
        "##skenario \n",
        "skenario_1 = {}\n",
        "skenario_1['1'] = clf_RF\n",
        "# skenario_1['2'] = clf_AB\n",
        "# skenario_1['3'] = clf_B\n",
        "# skenario_1['4'] = clf_ET\n",
        "skenario_1['5'] = clf_GB\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFjtADc8Enlc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "861ba582-9feb-4163-84e4-aae3714fa4a8"
      },
      "source": [
        "for i in skenario_1:\n",
        "    \n",
        "    clf_skenario = skenario_1[i]\n",
        "#     print('komposisi', i)\n",
        "\n",
        "    \n",
        "    result_SKLearn = validasi_model(clf_skenario,X_new,y_new,5)\n",
        "#     print(result_SKLearn)\n",
        "    \n",
        "    nama_file = 'drive/My Drive/Deteksi fraud/hasil/RUS/ULB/k_folds/komposisi999.csv'\n",
        "    nama_file = nama_file.replace('999',str(i))\n",
        "\n",
        "    result_SKLearn.to_csv(nama_file, sep=';',index=False)\n",
        "                \n",
        "\n",
        "df_result = pd.DataFrame()\n",
        "for i in skenario_1:\n",
        "    nama_file = 'drive/My Drive/Deteksi fraud/hasil/RUS/ULB/k_folds/komposisi999.csv'\n",
        "    nama_file = nama_file.replace('999',str(i))\n",
        "    df_komposisi = pd.read_csv(nama_file,sep=\";\")\n",
        "    df_result = df_result.append(df_komposisi.iloc[5:,:])\n",
        "    \n",
        "df_result.insert(loc=0, column='No', value=list(range(df_result.shape[0])))\n",
        "df_result = df_result.set_index('No')\n",
        "\n",
        "del df_result.index.name\n",
        "\n",
        "df_result.to_csv('drive/My Drive/Deteksi fraud/hasil/RUS/ULB/k_folds/result.csv', sep=';',index=False)\n",
        "df_result      \n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Akurasi</th>\n",
              "      <th>Sensitivity</th>\n",
              "      <th>Specifity</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>Waktu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.925547</td>\n",
              "      <td>0.882868</td>\n",
              "      <td>0.968245</td>\n",
              "      <td>0.965915</td>\n",
              "      <td>0.882868</td>\n",
              "      <td>0.921084</td>\n",
              "      <td>0.065912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.918248</td>\n",
              "      <td>0.894878</td>\n",
              "      <td>0.941989</td>\n",
              "      <td>0.940859</td>\n",
              "      <td>0.894878</td>\n",
              "      <td>0.915622</td>\n",
              "      <td>0.118207</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Akurasi  Sensitivity  Specifity  precision    recall  f1_score     Waktu\n",
              "0  0.925547     0.882868   0.968245   0.965915  0.882868  0.921084  0.065912\n",
              "1  0.918248     0.894878   0.941989   0.940859  0.894878  0.915622  0.118207"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMtobrSQ0pYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPR_NhSvERAg",
        "colab_type": "text"
      },
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxJAonkgF1Q-",
        "colab_type": "text"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PKSigBeFzxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validasi_testing (clf,X,y):\n",
        "    testing_result = testing(clf,X,y)\n",
        "    df_result = pd.DataFrame(data= testing_result, columns=['Akurasi','Sensitivity','Specifity','precision','recall','f1_score'])\n",
        "\n",
        "    df_result.insert(loc=0, column='No', value=list(range(1,df_result.shape[0]+1)))\n",
        "    df_result = df_result.set_index('No')\n",
        "\n",
        "    del df_result.index.name\n",
        "\n",
        "#     df_result = df_result.append(df_result.describe()[1:2])\n",
        "    \n",
        "    return df_result\n",
        "# result_SKLearn = result_SKLearn.append('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rONoLKz4r-E",
        "colab_type": "code",
        "outputId": "e69a3119-ffe0-4805-bdde-99702f9dea65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "n_tree = 100\n",
        "# clf_RF_ = RandomForestClassifier(random_state=1,n_estimators=n_tree, max_features='sqrt')\n",
        "clf_RF.fit(X_new,y_new)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
              "                       n_jobs=None, oob_score=False, random_state=1, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdJ8s5j-5aet",
        "colab_type": "code",
        "outputId": "f3523dd5-a96f-4c84-e098-5376befb775f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "n_tree = 100\n",
        "# clf = RandomForestClassifier(random_state=1,n_estimators=n_tree, max_features='sqrt')\n",
        "# clf_GB = GradientBoostingClassifier(random_state=1,n_estimators=50)\n",
        "\n",
        "clf_GB.fit(X_new,y_new)\n",
        "\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
              "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
              "                           max_features=None, max_leaf_nodes=None,\n",
              "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                           min_samples_leaf=1, min_samples_split=2,\n",
              "                           min_weight_fraction_leaf=0.0, n_estimators=50,\n",
              "                           n_iter_no_change=None, presort='auto',\n",
              "                           random_state=1, subsample=1.0, tol=0.0001,\n",
              "                           validation_fraction=0.1, verbose=0,\n",
              "                           warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGlRYuLODU33",
        "colab_type": "code",
        "outputId": "9eb7bbff-3b77-487d-d69c-daa2e2b78236",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "result = {}\n",
        "for i in skenario_1:\n",
        "  \n",
        "    clf_skenario = skenario_1[i]\n",
        "    result[i] = validasi_testing(clf_skenario,X_test,y_test)\n",
        "    \n",
        "                \n",
        "df_result = pd.DataFrame()\n",
        "for i in skenario_1:\n",
        "    df_result = df_result.append(result[i])\n",
        "    \n",
        "df_result.insert(loc=0, column='No', value=list(range(df_result.shape[0])))\n",
        "df_result = df_result.set_index('No')\n",
        "\n",
        "del df_result.index.name\n",
        "\n",
        "\n",
        "\n",
        "nama_file = 'drive/My Drive/Deteksi fraud/hasil/RUS/ULB/testing/result.csv'\n",
        "\n",
        "df_result.to_csv(nama_file, sep=';',index=False)\n",
        "\n",
        "df_result"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Akurasi</th>\n",
              "      <th>Sensitivity</th>\n",
              "      <th>Specifity</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.972613</td>\n",
              "      <td>0.925676</td>\n",
              "      <td>0.972695</td>\n",
              "      <td>0.055556</td>\n",
              "      <td>0.925676</td>\n",
              "      <td>0.104820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.955900</td>\n",
              "      <td>0.932432</td>\n",
              "      <td>0.955941</td>\n",
              "      <td>0.035421</td>\n",
              "      <td>0.932432</td>\n",
              "      <td>0.068249</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Akurasi  Sensitivity  Specifity  precision    recall  f1_score\n",
              "0  0.972613     0.925676   0.972695   0.055556  0.925676  0.104820\n",
              "1  0.955900     0.932432   0.955941   0.035421  0.932432  0.068249"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QphNuVUILK4Q",
        "colab_type": "text"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfY-qzrMLM4C",
        "colab_type": "text"
      },
      "source": [
        "**testing balance data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXW2-WxLC18g",
        "colab_type": "code",
        "outputId": "55a14e56-aa19-44c1-cb54-f797bb1a8a31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "y_test.value_counts()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    85295\n",
              "1      148\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA73mcnjHUoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test = X_test.copy()\n",
        "df_test['Class'] = y_test.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcvIT4GTHUre",
        "colab_type": "code",
        "outputId": "cc74d850-9340-44f3-806c-a163e571c135",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "# Since our classes are highly skewed we should make them equivalent in order to have a normal distribution of the classes.\n",
        "\n",
        "# Lets shuffle the data before creating the subsamples\n",
        "df_copy = df_test.copy()\n",
        "# df_copy = df_copy.sample(frac=1)\n",
        "\n",
        "fraud_df = df_copy.loc[df_copy['Class'] == 1]\n",
        "non_fraud_df = df_copy.loc[df_copy['Class'] == 0].sample(n=148,random_state=1)\n",
        "\n",
        "normal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n",
        "\n",
        "# Shuffle dataframe rows\n",
        "df_new = normal_distributed_df.sample(frac=1, random_state=1)\n",
        "df_new = df_new.reset_index()\n",
        "df_new = df_new.drop('index', axis=1)\n",
        "df_new.head()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>162903.0</td>\n",
              "      <td>-0.390568</td>\n",
              "      <td>0.270001</td>\n",
              "      <td>1.085434</td>\n",
              "      <td>-0.464380</td>\n",
              "      <td>-0.279046</td>\n",
              "      <td>-0.507906</td>\n",
              "      <td>0.218688</td>\n",
              "      <td>-0.041113</td>\n",
              "      <td>0.762716</td>\n",
              "      <td>-0.446903</td>\n",
              "      <td>-1.363403</td>\n",
              "      <td>-0.449710</td>\n",
              "      <td>-0.733004</td>\n",
              "      <td>-0.280190</td>\n",
              "      <td>0.000988</td>\n",
              "      <td>0.329930</td>\n",
              "      <td>-0.570067</td>\n",
              "      <td>0.240442</td>\n",
              "      <td>-0.386314</td>\n",
              "      <td>-0.320266</td>\n",
              "      <td>0.253206</td>\n",
              "      <td>0.876503</td>\n",
              "      <td>-0.017118</td>\n",
              "      <td>0.016664</td>\n",
              "      <td>-0.422901</td>\n",
              "      <td>0.539258</td>\n",
              "      <td>-0.163523</td>\n",
              "      <td>0.026458</td>\n",
              "      <td>25.89</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>129955.0</td>\n",
              "      <td>1.884704</td>\n",
              "      <td>0.535843</td>\n",
              "      <td>-1.116821</td>\n",
              "      <td>3.498523</td>\n",
              "      <td>1.050070</td>\n",
              "      <td>0.480142</td>\n",
              "      <td>0.395467</td>\n",
              "      <td>-0.080441</td>\n",
              "      <td>-1.180259</td>\n",
              "      <td>1.412192</td>\n",
              "      <td>-1.530856</td>\n",
              "      <td>-0.049783</td>\n",
              "      <td>0.895820</td>\n",
              "      <td>0.191061</td>\n",
              "      <td>-0.510240</td>\n",
              "      <td>1.050241</td>\n",
              "      <td>-1.090546</td>\n",
              "      <td>-0.668929</td>\n",
              "      <td>-1.233169</td>\n",
              "      <td>-0.096197</td>\n",
              "      <td>-0.268442</td>\n",
              "      <td>-0.925170</td>\n",
              "      <td>0.271971</td>\n",
              "      <td>-0.042794</td>\n",
              "      <td>-0.184396</td>\n",
              "      <td>-0.358618</td>\n",
              "      <td>-0.048632</td>\n",
              "      <td>-0.032508</td>\n",
              "      <td>56.71</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>159203.0</td>\n",
              "      <td>2.230196</td>\n",
              "      <td>-1.351494</td>\n",
              "      <td>-1.011452</td>\n",
              "      <td>-1.668003</td>\n",
              "      <td>-1.011959</td>\n",
              "      <td>-0.351587</td>\n",
              "      <td>-1.053100</td>\n",
              "      <td>-0.130973</td>\n",
              "      <td>-1.650390</td>\n",
              "      <td>1.708163</td>\n",
              "      <td>0.869462</td>\n",
              "      <td>0.365784</td>\n",
              "      <td>1.240951</td>\n",
              "      <td>-0.381091</td>\n",
              "      <td>-0.980562</td>\n",
              "      <td>-0.459717</td>\n",
              "      <td>0.212848</td>\n",
              "      <td>0.254881</td>\n",
              "      <td>0.142991</td>\n",
              "      <td>-0.311319</td>\n",
              "      <td>-0.098906</td>\n",
              "      <td>0.173737</td>\n",
              "      <td>0.230330</td>\n",
              "      <td>0.772078</td>\n",
              "      <td>-0.159950</td>\n",
              "      <td>-0.221738</td>\n",
              "      <td>0.002684</td>\n",
              "      <td>-0.048924</td>\n",
              "      <td>33.39</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>139279.0</td>\n",
              "      <td>-1.652409</td>\n",
              "      <td>-2.815875</td>\n",
              "      <td>2.317561</td>\n",
              "      <td>-1.209682</td>\n",
              "      <td>0.890838</td>\n",
              "      <td>-0.635322</td>\n",
              "      <td>-1.924706</td>\n",
              "      <td>0.409848</td>\n",
              "      <td>0.421943</td>\n",
              "      <td>0.193755</td>\n",
              "      <td>-0.321328</td>\n",
              "      <td>-0.406484</td>\n",
              "      <td>-1.057505</td>\n",
              "      <td>-1.121810</td>\n",
              "      <td>-2.183406</td>\n",
              "      <td>0.986740</td>\n",
              "      <td>0.119273</td>\n",
              "      <td>-0.416791</td>\n",
              "      <td>1.177313</td>\n",
              "      <td>0.667667</td>\n",
              "      <td>0.367494</td>\n",
              "      <td>0.738055</td>\n",
              "      <td>0.243123</td>\n",
              "      <td>-0.335769</td>\n",
              "      <td>-0.373336</td>\n",
              "      <td>-0.246704</td>\n",
              "      <td>-0.051461</td>\n",
              "      <td>-0.026657</td>\n",
              "      <td>47.48</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>26553.0</td>\n",
              "      <td>-3.696718</td>\n",
              "      <td>3.343293</td>\n",
              "      <td>-1.346614</td>\n",
              "      <td>1.121609</td>\n",
              "      <td>-1.740855</td>\n",
              "      <td>-0.154529</td>\n",
              "      <td>-1.533241</td>\n",
              "      <td>2.542613</td>\n",
              "      <td>0.186620</td>\n",
              "      <td>0.579849</td>\n",
              "      <td>-1.864397</td>\n",
              "      <td>0.165121</td>\n",
              "      <td>-1.233912</td>\n",
              "      <td>1.552874</td>\n",
              "      <td>0.294423</td>\n",
              "      <td>-0.525677</td>\n",
              "      <td>1.433250</td>\n",
              "      <td>-0.278846</td>\n",
              "      <td>0.704639</td>\n",
              "      <td>0.041674</td>\n",
              "      <td>0.000941</td>\n",
              "      <td>-0.065910</td>\n",
              "      <td>0.183955</td>\n",
              "      <td>-0.327592</td>\n",
              "      <td>0.263069</td>\n",
              "      <td>-0.212225</td>\n",
              "      <td>-0.237463</td>\n",
              "      <td>-0.101546</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0  162903.0 -0.390568  0.270001  1.085434  ... -0.163523  0.026458   25.89      0\n",
              "1  129955.0  1.884704  0.535843 -1.116821  ... -0.048632 -0.032508   56.71      0\n",
              "2  159203.0  2.230196 -1.351494 -1.011452  ...  0.002684 -0.048924   33.39      0\n",
              "3  139279.0 -1.652409 -2.815875  2.317561  ... -0.051461 -0.026657   47.48      0\n",
              "4   26553.0 -3.696718  3.343293 -1.346614  ... -0.237463 -0.101546    1.00      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdxseegfHnL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_ = df_new.drop('Class', axis=1)\n",
        "y_test_ = df_new['Class'].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ktpSIR_QPJt",
        "colab_type": "code",
        "outputId": "9b102d70-bbff-4acd-c0f0-f5335ff79e3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "y_test_.value_counts()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    148\n",
              "0    148\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiDXkbxkHnJY",
        "colab_type": "code",
        "outputId": "8c47b610-bc46-4aed-cab4-33b7ccbce2c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "result = {}\n",
        "for i in skenario_1:\n",
        "  \n",
        "    clf_skenario = skenario_1[i]\n",
        "    result[i] = validasi_testing(clf_skenario,X_test_,y_test_)\n",
        "    \n",
        "                \n",
        "df_result = pd.DataFrame()\n",
        "for i in skenario_1:\n",
        "    df_result = df_result.append(result[i])\n",
        "    \n",
        "df_result.insert(loc=0, column='No', value=list(range(df_result.shape[0])))\n",
        "df_result = df_result.set_index('No')\n",
        "\n",
        "del df_result.index.name\n",
        "\n",
        "\n",
        "nama_file = 'drive/My Drive/Deteksi fraud/hasil/RUS/ULB/testing_balanced/result.csv'\n",
        "\n",
        "df_result.to_csv(nama_file, sep=';',index=False)\n",
        "\n",
        "df_result\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Akurasi</th>\n",
              "      <th>Sensitivity</th>\n",
              "      <th>Specifity</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.932432</td>\n",
              "      <td>0.925676</td>\n",
              "      <td>0.939189</td>\n",
              "      <td>0.938356</td>\n",
              "      <td>0.925676</td>\n",
              "      <td>0.931973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.942568</td>\n",
              "      <td>0.932432</td>\n",
              "      <td>0.952703</td>\n",
              "      <td>0.951724</td>\n",
              "      <td>0.932432</td>\n",
              "      <td>0.941980</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Akurasi  Sensitivity  Specifity  precision    recall  f1_score\n",
              "0  0.932432     0.925676   0.939189   0.938356  0.925676  0.931973\n",
              "1  0.942568     0.932432   0.952703   0.951724  0.932432  0.941980"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSpHdpTbHOMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWjzRaCzHPAe",
        "colab_type": "text"
      },
      "source": [
        "------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlyJrFOBHTxT",
        "colab_type": "text"
      },
      "source": [
        "## feature importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsEmQWswHnGD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "outputId": "c6f0e2d5-96a5-42de-b0b3-b14482ccbb3a"
      },
      "source": [
        "#RF\n",
        "importances = clf_RF.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "fitur_importance =[]\n",
        "for f in range(X_new.shape[1]):\n",
        "    if  importances[indices[f]] > 0 :\n",
        "        fitur_importance.append([X_new.columns[indices[f]],importances[indices[f]]])\n",
        "        print(\"%2d) %-*s %f\" % (f + 1, 30,\n",
        "        X_new.columns[indices[f]],\n",
        "        importances[indices[f]]))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 1) V14                            0.216167\n",
            " 2) V12                            0.162343\n",
            " 3) V4                             0.128359\n",
            " 4) V17                            0.123934\n",
            " 5) V11                            0.079683\n",
            " 6) V2                             0.048816\n",
            " 7) V10                            0.024321\n",
            " 8) V19                            0.021648\n",
            " 9) V20                            0.015250\n",
            "10) V3                             0.015011\n",
            "11) V8                             0.014273\n",
            "12) V15                            0.012697\n",
            "13) V27                            0.011980\n",
            "14) V16                            0.011305\n",
            "15) Time                           0.011222\n",
            "16) V5                             0.011137\n",
            "17) V26                            0.010253\n",
            "18) Amount                         0.008299\n",
            "19) V7                             0.007976\n",
            "20) V18                            0.007733\n",
            "21) V1                             0.007666\n",
            "22) V22                            0.007360\n",
            "23) V13                            0.007281\n",
            "24) V9                             0.007010\n",
            "25) V24                            0.006108\n",
            "26) V23                            0.006101\n",
            "27) V6                             0.006067\n",
            "28) V28                            0.004178\n",
            "29) V21                            0.003551\n",
            "30) V25                            0.002272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBJaPGAzHc7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_FI = pd.DataFrame(data=fitur_importance,columns=['fitur','value'])\n",
        "# # np.array(df_FI['fitur'])\n",
        "# df_FI"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZETmMbLBHdJe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "9d89b3b8-d91f-484a-c08e-e44f90c979c3"
      },
      "source": [
        "#GB\n",
        "importances = clf_GB.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "fitur_importance =[]\n",
        "for f in range(X_new.shape[1]):\n",
        "    if  importances[indices[f]] > 0 :\n",
        "        fitur_importance.append([X_new.columns[indices[f]],importances[indices[f]]])\n",
        "        print(\"%2d) %-*s %f\" % (f + 1, 30,\n",
        "        X_new.columns[indices[f]],\n",
        "        importances[indices[f]]))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 1) V14                            0.732430\n",
            " 2) V12                            0.068184\n",
            " 3) V4                             0.059858\n",
            " 4) V20                            0.019131\n",
            " 5) V3                             0.014287\n",
            " 6) V7                             0.013613\n",
            " 7) V8                             0.012290\n",
            " 8) V19                            0.011904\n",
            " 9) V11                            0.008781\n",
            "10) V18                            0.008405\n",
            "11) V9                             0.007580\n",
            "12) V22                            0.006856\n",
            "13) V15                            0.006127\n",
            "14) V17                            0.004569\n",
            "15) V26                            0.004341\n",
            "16) Amount                         0.004033\n",
            "17) V6                             0.002704\n",
            "18) V23                            0.002422\n",
            "19) V13                            0.002317\n",
            "20) V27                            0.002014\n",
            "21) V21                            0.001691\n",
            "22) V5                             0.001535\n",
            "23) V28                            0.001289\n",
            "24) V25                            0.001142\n",
            "25) V10                            0.001029\n",
            "26) V16                            0.000638\n",
            "27) V1                             0.000533\n",
            "28) V2                             0.000154\n",
            "29) Time                           0.000144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIOw_LXxHdMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_FI = pd.DataFrame(data=fitur_importance,columns=['fitur','value'])\n",
        "# # np.array(df_FI['fitur'])\n",
        "# df_FI"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrEYG1rS0pYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dot_data = StringIO()  \n",
        "# tree.export_graphviz(clf.estimators_[8], out_file=dot_data,  \n",
        "#                          feature_names=X_new.columns)  \n",
        "# graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "# Image(graph.create_png())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnK3ml2W0pYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dot_data = StringIO()  \n",
        "# tree.export_graphviz(clf_DT,out_file=dot_data,feature_names=X_new.columns)  \n",
        "# graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "# Image(graph.create_png())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvPu11jQHKF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mROyAscHMQX",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtRSEB3IDbpE",
        "colab_type": "text"
      },
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iduJYQkSDfp9",
        "colab_type": "text"
      },
      "source": [
        "## Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLCBXkiu0pYg",
        "colab_type": "code",
        "outputId": "5f9d5cc0-23eb-49ba-ebe0-91131b05ddf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        }
      },
      "source": [
        "print(__doc__)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from time import time\n",
        "from scipy.stats import randint as sp_randint\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# get some data\n",
        "digits = load_digits()\n",
        "X, y = digits.data, digits.target\n",
        "\n",
        "# build a classifier\n",
        "clf = RandomForestClassifier(random_state=1,n_jobs=-1)\n",
        "\n",
        "\n",
        "# Utility function to report best scores\n",
        "def report(results, n_top=3):\n",
        "    for i in range(1, n_top + 1):\n",
        "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
        "        for candidate in candidates:\n",
        "            print(\"Model with rank: {0}\".format(i))\n",
        "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
        "                  results['mean_test_score'][candidate],\n",
        "                  results['std_test_score'][candidate]))\n",
        "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
        "            print(\"\")\n",
        "\n",
        "\n",
        "# specify parameters and distributions to sample from\n",
        "param_dist = {\n",
        "#                 \"max_depth\": [5,9,11,15 ],\n",
        "              'n_estimators' : [10,25,50,75,100],\n",
        "              \"max_features\": ['sqrt','log2',None],\n",
        "#               \"min_samples_split\": sp_randint(2, 11),\n",
        "#               \"bootstrap\": [True, False],\n",
        "#               \"criterion\": [\"gini\", \"entropy\"]\n",
        "             }\n",
        "\n",
        "# run randomized search\n",
        "n_iter_search = 20\n",
        "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
        "                                   n_iter=n_iter_search, cv=5, iid=False,random_state=1)\n",
        "\n",
        "start = time()\n",
        "random_search.fit(X_new, y_new)\n",
        "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
        "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
        "report(random_search.cv_results_)\n",
        "\n",
        "# use a full grid over all parameters\n",
        "param_grid = {\n",
        "#                 \"max_depth\": [5,9,11,15 ],\n",
        "              'n_estimators' : [10,25,50,75,100],\n",
        "              \"max_features\": ['sqrt','log2',None],\n",
        "#               \"min_samples_split\": sp_randint(2, 11),\n",
        "#               \"min_samples_split\": [2, 3, 10],\n",
        "#               \"bootstrap\": [True, False],\n",
        "#               \"criterion\": [\"gini\", \"entropy\"]\n",
        "             }\n",
        "\n",
        "# run grid search\n",
        "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5, iid=False)\n",
        "start = time()\n",
        "grid_search.fit(X_new, y_new)\n",
        "\n",
        "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
        "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
        "report(grid_search.cv_results_)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Automatically created module for IPython interactive environment\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 15 is smaller than n_iter=20. Running 15 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "RandomizedSearchCV took 29.75 seconds for 20 candidates parameter settings.\n",
            "Model with rank: 1\n",
            "Mean validation score: 0.932 (std: 0.015)\n",
            "Parameters: {'n_estimators': 10, 'max_features': 'sqrt'}\n",
            "\n",
            "Model with rank: 2\n",
            "Mean validation score: 0.929 (std: 0.017)\n",
            "Parameters: {'n_estimators': 75, 'max_features': 'sqrt'}\n",
            "\n",
            "Model with rank: 2\n",
            "Mean validation score: 0.929 (std: 0.020)\n",
            "Parameters: {'n_estimators': 75, 'max_features': None}\n",
            "\n",
            "GridSearchCV took 27.95 seconds for 15 candidate parameter settings.\n",
            "Model with rank: 1\n",
            "Mean validation score: 0.932 (std: 0.015)\n",
            "Parameters: {'max_features': 'sqrt', 'n_estimators': 10}\n",
            "\n",
            "Model with rank: 2\n",
            "Mean validation score: 0.929 (std: 0.017)\n",
            "Parameters: {'max_features': 'sqrt', 'n_estimators': 75}\n",
            "\n",
            "Model with rank: 2\n",
            "Mean validation score: 0.929 (std: 0.020)\n",
            "Parameters: {'max_features': None, 'n_estimators': 75}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIRTSU6d0pZd",
        "colab_type": "code",
        "outputId": "0e81e631-6429-4236-fa70-8dd954e6b92e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        }
      },
      "source": [
        "print(__doc__)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from time import time\n",
        "from scipy.stats import randint as sp_randint\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# get some data\n",
        "digits = load_digits()\n",
        "X, y = digits.data, digits.target\n",
        "\n",
        "# build a classifier\n",
        "clf = GradientBoostingClassifier(random_state=1)\n",
        "\n",
        "\n",
        "# Utility function to report best scores\n",
        "def report(results, n_top=3):\n",
        "    for i in range(1, n_top + 1):\n",
        "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
        "        for candidate in candidates:\n",
        "            print(\"Model with rank: {0}\".format(i))\n",
        "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
        "                  results['mean_test_score'][candidate],\n",
        "                  results['std_test_score'][candidate]))\n",
        "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
        "            print(\"\")\n",
        "\n",
        "\n",
        "# specify parameters and distributions to sample from\n",
        "param_dist = {\"max_depth\": [3,5,9],\n",
        "              'n_estimators' : [10,25,50,75,100],\n",
        "#               \"max_features\": sp_randint(1, 11),\n",
        "#               \"min_samples_split\": sp_randint(2, 11),\n",
        "#               \"bootstrap\": [True, False],\n",
        "#               \"criterion\": [\"gini\", \"entropy\"]\n",
        "             }\n",
        "\n",
        "# run randomized search\n",
        "n_iter_search = 20\n",
        "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
        "                                   n_iter=n_iter_search, cv=5, iid=False,random_state=1)\n",
        "\n",
        "start = time()\n",
        "random_search.fit(X_new, y_new)\n",
        "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
        "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
        "report(random_search.cv_results_)\n",
        "\n",
        "# use a full grid over all parameters\n",
        "param_grid = {\"max_depth\": [3,5,9],\n",
        "              'n_estimators' : [10,25,50,75,100],\n",
        "#               \"max_features\": [1, 3, 10],\n",
        "#               \"min_samples_split\": [2, 3, 10],\n",
        "#               \"bootstrap\": [True, False],\n",
        "#               \"criterion\": [\"gini\", \"entropy\"]\n",
        "             }\n",
        "\n",
        "# run grid search\n",
        "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5, iid=False)\n",
        "start = time()\n",
        "grid_search.fit(X_new, y_new)\n",
        "\n",
        "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
        "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
        "report(grid_search.cv_results_)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Automatically created module for IPython interactive environment\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 15 is smaller than n_iter=20. Running 15 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "RandomizedSearchCV took 20.18 seconds for 20 candidates parameter settings.\n",
            "Model with rank: 1\n",
            "Mean validation score: 0.927 (std: 0.016)\n",
            "Parameters: {'n_estimators': 50, 'max_depth': 3}\n",
            "\n",
            "Model with rank: 2\n",
            "Mean validation score: 0.926 (std: 0.008)\n",
            "Parameters: {'n_estimators': 10, 'max_depth': 3}\n",
            "\n",
            "Model with rank: 3\n",
            "Mean validation score: 0.926 (std: 0.016)\n",
            "Parameters: {'n_estimators': 25, 'max_depth': 3}\n",
            "\n",
            "GridSearchCV took 20.44 seconds for 15 candidate parameter settings.\n",
            "Model with rank: 1\n",
            "Mean validation score: 0.927 (std: 0.016)\n",
            "Parameters: {'max_depth': 3, 'n_estimators': 50}\n",
            "\n",
            "Model with rank: 2\n",
            "Mean validation score: 0.926 (std: 0.008)\n",
            "Parameters: {'max_depth': 3, 'n_estimators': 10}\n",
            "\n",
            "Model with rank: 3\n",
            "Mean validation score: 0.926 (std: 0.016)\n",
            "Parameters: {'max_depth': 3, 'n_estimators': 25}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjYemfybDjUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}